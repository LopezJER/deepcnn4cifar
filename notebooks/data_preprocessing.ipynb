{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cifar-10 images sre 32X32 pixels \n",
    "vgg get 224X224 pixels.\n",
    "make sure to upsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n",
    "The classes are completely mutually exclusive. There is no overlap between automobiles and trucks. \"Automobile\" includes sedans, SUVs, things of that sort. \"Truck\" includes only big trucks. Neither includes pickup trucks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loaded in this way, each of the batch files contains a dictionary with the following elements:\n",
    "\n",
    "data -- a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "\n",
    "labels -- a list of 10000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data.\n",
    "\n",
    "The dataset contains another file, called batches.meta. It too contains a Python dictionary object. It has the following entries:\n",
    "label_names -- a 10-element list which gives meaningful names to the numeric labels in the labels array described above. For example, label_names[0] == \"airplane\", label_names[1] == \"automobile\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocess_image_for_vgg16\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unpickle\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# === Constants ===\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'preprocessing'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocessing import preprocess_image_for_vgg16\n",
    "from utils import unpickle\n",
    "\n",
    "# === Constants ===\n",
    "DATA_DIR = r\"D:\\CIFAR-10\\cifar-10-python\\cifar-10-batches-py\"\n",
    "TARGET_SIZE = (224, 224)\n",
    "\n",
    "\n",
    "# Visualize Before and After Preprocessing\n",
    "batch_path = os.path.join(DATA_DIR, \"data_batch_1\")\n",
    "batch = unpickle(batch_path)\n",
    "\n",
    "# Get a random image and label\n",
    "images, labels = batch[b\"data\"], batch[b\"labels\"]\n",
    "random_idx = np.random.randint(0, len(images))\n",
    "raw_image = (\n",
    "    images[random_idx].reshape(3, 32, 32).transpose(1, 2, 0).astype(np.float32) / 255.0\n",
    ")\n",
    "processed_image = preprocess_image_for_vgg16(images[random_idx], TARGET_SIZE)\n",
    "\n",
    "# Display images\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(raw_image)\n",
    "plt.title(\"Original (32x32)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(processed_image)\n",
    "plt.title(\"Preprocessed (224x224)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
